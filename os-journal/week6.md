# Week 6 - Performance Evaluation and Analysis

## Phase 6 Overview

Week 6 focuses on evaluating the performance of the Raspberry Pi OS 
Lite server under different workloads. The aim is to understand system 
behaviour by monitoring CPU, memory, disk I/O, network, and thermal 
characteristics, and to identify potential bottlenecks or optimisation 
opportunities. All administration and testing were performed remotely 
from the Windows 11 workstation via SSH.

## Testing Methodology

### Baseline System Performance

Before introducing any workload, I recorded idle system metrics using 
a simple script that logs usage over 5 minutes then uses grep to get
data out of log files, which is then written to a summary log file.

This ensures that later measurements reflect the impact of workloads 
rather than background processes.

Here is the script used to measure and filter data: 
[run_tests_5min.sh](scripts/run_tests_5min.sh)

And here is the log file output for the baseline (no unnessesary 
processes running): 
[Summary.log](logs/Baseline.log)

#### Baseline Performance Results and Analysis

The baseline measurements represent the system in an idle state, with 
no user applications running other than essential background services
and the monitoring script itself. The results provide a reference 
point against which later workload tests can be compared.

### CPU and Load Analysis

![cpu results](img/week6/cpu_baseline.png)

During the baseline test, the 1 minute load average sat in the range 
of 0.14 - 0.28 this is fine as the Raspberry Pi has 4 cores which 
indicates that the system was not under stress during the test. 

Cpu utilisation was measured using idle time, with the lowest idle 
percentage being 93.8%, with an average percentage of 95.42%. This 
confirms that the Raspberry Pi was largely inactive during baseline
measurement and that no background processes were consuming 
significant CPU time.

###  Memory Analysis

![Memory Analysis](img/week6/memory_baseline.png)

Baseline memory usage remained stable across all five measurement 
intervals. Active system memory usage ranged between approximately 304
MiB and 308 MiB. This represents less than 5% of total available RAM,
indicating that the system was largely idle and under no pressure.

Free memory remained high throughout the test, averaging around 7.05
GiB, while buffer and cache usage remained constant at approximately
556 MiB. This behaviour is expected on Linux systems, where unused
memory is opportunistically used for filesystem caching to improve performance without impacting application availability.

Swap usage remained at 0 MiB for all five iterations, with the full 
2048 MiB of swap space available at all times. This confirms that the 
system did not require paging to disk and that physical memory was 
more than sufficient during baseline operation.

### Disk and I/O Performance

![ Disk and I/O ](img/week6/DiskIO_baseline.png)

Disk usage remained constant throughout the baseline test, with 
approximately 5% of the root filesystem utilised. Disk I/O activity 
was minimal outside of the synthetic read/write tests, indicating no 
background disk-intensive processes.

Measured write speeds ranged between 12.0 and 21.9 MB/s, while read 
speeds were significantly higher, reaching 1.2 GB/s. This behaviour is 
consistent with SD card performance characteristics and Linux 
filesystem caching.

### Network Analysis

![Network Analysis](img/week6/network_baseline.png)

Network activity was monitored on the wlan0 interface during the 
5-minute baseline test. Across five iterations, both received (RX) and 
transmitted (TX) packet counts increased steadily, reflecting normal 
background traffic generated by SSH connectivity and system services.

No receive or transmit errors were observed, and packet drops remained 
constant at a low level (RX-DRP = 10), indicating stable wireless 
performance with no signs of congestion or retransmission issues. 
Overall, network behaviour remained consistent and reliable under idle 
conditions, providing a stable baseline for comparison against 
network-intensive workloads in later tests.

### Thermal Behaviour Analysis

![Thermal Behaviour](img/week6/thermal_baseline.png)

During the 5-minute baseline test, CPU temperature remained stable, 
ranging between 37.4 °C and 39.4 °C across all five iterations. These 
values are well within safe operating limits for the Raspberry Pi 4 
and indicate effective passive cooling under idle conditions.

The throttling status remained 0x0 throughout the test, confirming 
that no thermal or voltage throttling occurred. This shows that the 
system had sufficient thermal headroom during baseline operation and 
provides confidence that any performance changes observed in later 
workload tests can be attributed to application load rather than 
thermal constraints.

### Baseline Performance Summary

Overall, the baseline results show that the Raspberry Pi OS Lite 
server operates efficiently under idle conditions. CPU utilisation 
remained low, memory usage was stable with no swap activity, disk 
usage showed no unexpected I/O, network activity was minimal and 
error-free, and system temperatures remained well below throttling 
thresholds.

These results confirm that the system is in a healthy and stable state 
and provide a reliable reference point for evaluating the impact of 
application workloads in subsequent performance tests.


## Testing applications

This phase evaluates system behaviour under representative application 
workloads. For each test, the application and monitoring script were 
started simultaneously using a single shell command:

Each workload was then exercised for approximately five minutes to 
simulate typical usage patterns relevant to a headless Raspberry Pi 
server. System metrics were collected at one-minute intervals using 
the same monitoring methodology as the baseline test, ensuring results 
are directly comparable.

### FFmpeg Analysis

Command used: 
```bash
ffmpeg -f lavfi -i testsrc=size=1280x720 -t 300 -pix_fmt yuv420p testsrc.mp4
```
Results

[ffmpeg results](logs/FFmpeg.log)

FFmpeg significantly stressed the CPU, with the 1-minute load average rising from 0.2 to 6.87, exceeding available cores and indicating CPU saturation. CPU idle fell to 6.8%, confirming a CPU-bound workload. This bottleneck could be mitigated through hardware acceleration or reduced encoding complexity.

Memory usage increased modestly (~305 MiB → ~600 MiB) with no swap usage. Disk write speeds varied between 12–27 MB/s, while read speeds remained high due to caching.

CPU temperature peaked at 76.9 °C, but no throttling occurred, showing the Pi handled the workload stably however there is a potential increase in efficincy if I can get the temperature down. I could do this by installing a heatsink on the cpu or some other passive cooling addition.

In summary, FFmpeg stresses CPU and thermal limits, while memory, disk, and network remain largely unaffected.

### Memcached Analysis 

Commands used: 
```bash
memcached -m 512 -p 11221 -u nobody
memcslap -s 127.0.0.1:11221 -c 20 -e 100000 --test=get
```

Results

[Memcached results](logs/Memcached.log)

Memcached significantly stressed the CPU, with the 1-minute load average peaking at 15.50, far exceeding the available cores and indicating CPU saturation. CPU idle dropped to 0% during peak iterations, confirming a CPU-bound workload under high request load.

Memory usage increased substantially (780 MiB - 1.63 GiB), which is expected for an in-memory cache. No swap usage occurred, showing sufficient physical RAM was available.

Disk activity remained minimal, confirming Memcached operates almost entirely in memory. Network traffic increased steadily with no errors, indicating stable connectivity under load.

CPU temperature peaked at 67.2 °C with no throttling, showing the system handled the workload safely.

In summary, Memcached primarily stresses CPU and memory, with minimal disk impact and moderate network usage.


### SQlite Analysis 
Command used: 
```bash
sqlite3 test.db "CREATE TABLE perf_test (id INTEGER PRIMARY KEY, data TEXT);"

for i in {1..5000}; do
  sqlite3 test.db "INSERT INTO perf_test (data) VALUES ('test data $i');"
done

for i in {1..5000}; do
  sqlite3 test.db "SELECT * FROM perf_test WHERE id=$i;" > /dev/null
done
```

Results

[SQlite results](logs/sqlite3.log)

SQLite produced a moderate, bursty workload primarily affecting disk I/O rather than CPU. The 1-minute load average peaked at 1.20, remaining well below core saturation and indicating that the workload was not CPU-bound. CPU idle stayed high (72–100%), confirming minimal processor stress.

Memory usage increased slightly from 319 MiB to 356 MiB, reflecting SQLite’s page caching, but no swap usage occurred, showing sufficient available RAM. Disk write speeds declined from an initial 35.5 MB/s to 12 MB/s as the test progressed, while read speeds remained high due to filesystem caching.

CPU temperature remained low, peaking at 47.2 °C, with no throttling detected. Overall, SQLite stresses disk I/O more than CPU or memory, making storage performance the primary limiting factor rather than compute or thermal constraints.

### iperf3 Analysis 
Command used: 
```bash
iperf3 -s -u

iperf3 -c 192.168.1.64 -t 300 -u 
```

Results

[iperf3 results](logs/iperf3.log)

The iperf tests evaluated network performance under sustained load, covering both throughput (TCP) and latency/reliability (UDP).

The TCP test transferred 409 GB over 5 minutes, achieving a consistent 11.7 Gbit/s on both sender and receiver with zero retransmissions. CPU load increased moderately (45–49% idle), memory usage remained low (315–325 MiB), and no network errors or drops were observed on wlan0, indicating that the Raspberry Pi could handle high-throughput traffic. The stable TCP throughput and absence of retransmissions also suggest low and consistent latency during the test.

The UDP test at 1.05 Mbit/s confirmed network reliability under low-latency traffic. No packet loss occurred, and jitter was extremely low (0.000–0.122 ms), demonstrating minimal latency variation and highly stable wireless performance. CPU and memory usage remained minimal, and no interface errors or drops were detected.

Overall, these results demonstrate that the Raspberry Pi can sustain high TCP throughput while maintaining low-latency, reliable UDP performance, with no evident network bottlenecks under the tested conditions.

### Luanti Server Analysis
Command used: 
```bash
 sudo ./luantiserver --gameid minetest
```

Results

[Luanti Server results](logs/luantiserver.log)

The LuantiServer workload produced very low system load, with 1-minute load averages peaking at 0.42, far below the Pi’s 4-core capacity. CPU idle remained extremely high (94–100%), confirming that the server imposes minimal CPU stress.

Memory usage stayed stable at 315–330 MiB, with no swap usage, indicating ample free RAM and very light memory demand. Disk I/O showed moderate write speeds (12–20 MB/s) while read speeds were extremely high (1–1.4 GB/s), likely due to caching, confirming that storage was not a performance bottleneck.

Network activity was low to moderate on wlan0, with no errors or drops affecting traffic. CPU temperature remained low, peaking at 49.6 °C, and no throttling was detected.

Overall, LuantiServer runs as a lightweight service on the Raspberry Pi, stressing neither CPU, memory, nor storage, making it efficient for continuous operation without significant system impact.

## Tables and Graphs

### Results Table

| Application     | Iteration | Load 1min | Load 5min | Load 15min | CPU Idle (%) | Mem Used (MiB) | Swap Used (MiB) | Disk Write (MB/s) | Disk Read (GB/s) | Temp (°C) |
|-----------------|------|-------|-----------|------------|--------------|----------------|------------------|-------------------|------------------|-----------|
| LuantiServer    | 1 | 0.17 | 0.06 | 0.16 | 95.6 | 329.2 | 0 | 16.3 | 1.4 | 46.7 |
| LuantiServer    | 2 | 0.30 | 0.14 | 0.18 | 94.0 | 317.6 | 0 | 15.7 | 1.0 | 46.2 |
| LuantiServer    | 3 | 0.37 | 0.21 | 0.20 | 100  | 331.9 | 0 | 12.3 | 1.3 | 49.6 |
| LuantiServer    | 4 | 0.42 | 0.31 | 0.24 | 97.9 | 315.7 | 0 | 19.9 | 1.1 | 45.2 |
| LuantiServer    | 5 | 0.27 | 0.31 | 0.25 | 100  | 317.4 | 0 | 12.1 | 1.1 | 44.3 |
| SQLite          | 1 | 0.00 | 0.03 | 0.64 | 100  | 318.9 | 0 | 35.5 | 1.3 | 40.9 |
| SQLite          | 2 | 0.97 | 0.32 | 0.69 | 73.3 | 340.9 | 0 | 16.4 | 1.3 | 39.4 |
| SQLite          | 3 | 1.17 | 0.58 | 0.76 | 72.7 | 355.2 | 0 | 12.1 | 1.3 | 47.2 |
| SQLite          | 4 | 0.74 | 0.64 | 0.77 | 97.7 | 324.6 | 0 | 12.1 | 1.0 | 41.3 |
| SQLite          | 5 | 1.20 | 0.81 | 0.83 | 71.7 | 346.5 | 0 | 12.0 | 1.1 | 43.3 |
| iperf3          | 1 | 1.31 | 0.61 | 0.68 | 45.7 | 318.3 | 0 | 16.3 | 0.895 | 55.5 |
| iperf3          | 2 | 1.83 | 0.94 | 0.79 | 46.8 | 319.8 | 0 | 30.0 | 0.684 | 60.3 |
| iperf3          | 3 | 2.03 | 1.20 | 0.90 | 48.9 | 320.2 | 0 | 11.9 | 0.879 | 61.3 |
| iperf3          | 4 | 2.35 | 1.53 | 1.04 | 44.7 | 324.4 | 0 | 16.8 | 0.893 | 63.3 |
| iperf3          | 5 | 1.87 | 1.55 | 1.09 | 48.8 | 313.8 | 0 | 13.9 | 0.680 | 61.8 |
| FFmpeg          | 1 | 1.18 | 1.95 | 0.96 | 97.7 | 308.9 | 0 | 27.2 | 0.973 | 59.4 |
| FFmpeg          | 2 | 4.99 | 3.01 | 1.40 | 6.8  | 597.7 | 0 | 12.1 | 1.000 | 72.0 |
| FFmpeg          | 3 | 5.55 | 3.71 | 1.78 | 22.7 | 594.1 | 0 | 18.9 | 1.100 | 64.2 |
| FFmpeg          | 4 | 5.33 | 3.95 | 2.01 | 19.6 | 602.0 | 0 | 13.3 | 1.000 | 75.4 |
| FFmpeg          | 5 | 6.87 | 4.71 | 2.43 | 12.8 | 595.9 | 0 | 14.2 | 0.959 | 76.9 |
| Memcached       | 1 | 1.24 | 1.10 | 0.50 | 100  | 783.6  | 0 | 12.4 | 0.896 | 52.5 |
| Memcached       | 2 | 11.98| 4.65 | 1.79 | 0.0  | 1232.4 | 0 | 11.8 | 0.535 | 61.8 |
| Memcached       | 3 | 13.81| 6.47 | 2.64 | 10.4 | 1571.7 | 0 | 12.1 | 0.796 | 67.2 |
| Memcached       | 4 | 8.64 | 6.77 | 3.07 | 0.0  | 1632.2 | 0 | 16.0 | 1.200 | 64.7 |
| Memcached       | 5 | 15.50| 9.27 | 4.22 | 68.3 | 1605.8 | 0 | 13.4 | 0.744 | 67.2 |


### Load Averages
LuantiServer and SQLite remain consistently below a load of 1, indicating very low CPU pressure. iperf3 shows moderate sustained load due to network processing. ffmpeg and Memcached generate the highest load averages, clearly demonstrating CPU-bound behaviour under sustained workloads:

![alt text](docs/graphs/image.png)
![alt text](docs/graphs/image-1.png)
![alt text](docs/graphs/image-2.png)

### CPU Idle
CPU idle closely mirrors load behaviour. LuantiServer and SQLite retain high idle time, while iperf3 reduces idle to around 47%. ffmpeg and Memcached show the lowest idle percentages, confirming heavy CPU utilisation:

![alt text](docs/graphs/image-3.png)

### Memory Usage
Most applications use ~320–340 MiB of RAM. ffmpeg increases memory usage moderately, while Memcached is a clear outlier, consuming over 1.3 GiB due to its in-memory design. No swap usage occurred:

![alt text](docs/graphs/image-4.png)

### Disk I/O
Disk write throughput remains relatively stable across workloads, with SQLite and iperf3 slightly higher. Disk read performance is consistent across all tests, indicating storage is not a bottleneck.

![alt text](docs/graphs/image-6.png)
![alt text](docs/graphs/image-7.png)

### Temperature
Temperatures rise in line with CPU load. LuantiServer and SQLite remain cool, iperf3 shows moderate increase, and ffmpeg reaches the highest temperatures. No thermal throttling was observed.

![alt text](docs/graphs/image-5.png)

Bottlenecks and Optimisations:

CPU-bound workloads could benefit from multi-threading or hardware acceleration. Disk-bound workloads like SQLite could be improved with faster storage or batching. Network performance was strong and stable.

## Week 3 Comparison

The Week 6 results largely validated the expected resource profiles defined in Week 3, particularly for FFmpeg, SQLite, and iperf3. FFmpeg proved strongly CPU-bound with increased thermal output, while SQLite stressed disk I/O and iperf3 heavily utilised network resources with moderate CPU impact.

However, Memcached and LuantiServer differed from initial expectations. Memcached consumed significantly more CPU under load than anticipated, despite behaving as expected in terms of memory usage. LuantiServer imposed far lower CPU and memory demands than predicted, highlighting how workload intensity and user activity influence real-world resource consumption.

## Conclusion

This evaluation showed how different workloads impact a Raspberry Pi OS Lite server across CPU, memory, disk, network, and thermal metrics. Baseline results confirmed the system operates efficiently under idle conditions, providing a reliable reference for comparison.

CPU-intensive workloads such as FFmpeg and Memcached created the highest load and temperature increases, identifying the CPU as the primary bottleneck under sustained computation. Although no thermal throttling occurred, these results suggest that cooling improvements or workload optimisation could enhance performance. Memory usage varied by application, with Memcached consuming the most RAM as expected, while no workloads required swap, indicating sufficient physical memory.

SQLite primarily stressed disk I/O, with declining write throughput over time highlighting storage as a limiting factor for write tasks. In comparison, iperf3 demonstrated stable high-throughput, low-latency network performance, and LuantiServer imposed minimal system overhead, making it suitable for continuous operation.

Overall, the Raspberry Pi performs well for lightweight services and network workloads, but CPU- and disk-intensive applications expose clear performance limits. These findings reinforce the importance of matching workload demands to hardware capabilities in low-power deployments.
